{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Georgia; font-size:3em;color:#2462C0; font-style:bold\">\n",
    "Predicting Loan Repayment</h1><br>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/Loans-borrow-repay.jpg\"; style=\"height: 400px; width: 800px\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2 style=\"font-family: Georgia; font-size:2em;color:purple; font-style:bold\">\n",
    "Introduction</h2><br>\n",
    "The two most critical questions in the lending industry are: 1) How risky is the borrower? 2) Given the borrower's risk, should we lend him? The answer to the first question determines the interest rate the borrower would have. Interest rate measures among other things (such as time value of money) the riskness of the borrower. The riskier the borrower, the higher the interest rate. With interest rate in mind, we can then determine if the borrower is eligible for the loan.\n",
    "\n",
    "Investors (lenders) provide loans to borrowers in exchange for the promise of repayment with interest. That means the lender only makes profit (interest) if the borrower pays off the loan. However, if he doesn't repay the loan, then the lender loses money.\n",
    "\n",
    "We'll be using publicly available data from [LendingClub.com](https://www.LendingClub.com). The data covers the 9,578 loans funded by the platform between May 2007 and February 2010. The interest rate is provided to us for each borrower. Therefore, so we'll address the second question indirectly by trying to predict if the borrower will repay the loan by its mature date or not. Through this excerise we'll illustrate three modeling concepts:\n",
    "- What to do with missing values.\n",
    "- Techniques used with imbalanced classification problems.\n",
    "- Illustrate how to build an ensemble model that is built on top of other models (stacking), which most likely gives us a boost in performance.\n",
    "\n",
    "Below is a short description of each feature in the data set:\n",
    "- **credit_policy**: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n",
    "- **purpose**: The purpose of the loan such as: credit_card, debt_consolidation, etc.\n",
    "- **int_rate**: The interest rate of the loan (proportion).\n",
    "- **installment**: The monthly installments (\\$) owed by the borrower if the loan is funded.\n",
    "- **log_annual_inc**: The natural log of the annual income of the borrower.\n",
    "- **dti**: The debt-to-income ratio of the borrower.\n",
    "- **fico**: The FICO credit score of the borrower.\n",
    "- **days_with_cr_line**: The number of days the borrower has had a credit line.\n",
    "- **revol_bal**: The borrower's revolving balance.\n",
    "- **revol_util**: The borrower's revolving line utilization rate.\n",
    "- **inq_last_6mths**: The borrower's number of inquiries by creditors in the last 6 months.\n",
    "- **delinq_2yrs**: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n",
    "- **pub_rec**: The borrower's number of derogatory public records.\n",
    "- **not_fully_paid**: indicates whether the loan was not paid back in full (the borrower either defaulted or the borrower was deemed unlikely to pay it back).\n",
    "\n",
    "Let's load the data and check:\n",
    "- Data types of each feature\n",
    "- If we have missing values\n",
    "- If we have imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import fancyimpute\n",
    "from imblearn.pipeline import make_pipeline as imb_make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import Imputer, RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix,\n",
    "                             accuracy_score, roc_curve,\n",
    "                             precision_recall_curve, f1_score)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from scripts.plot_roc import plot_roc_and_pr_curves\n",
    "os.chdir(\"notebooks/\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mData types:\n",
      "-----------\n",
      "\u001b[30mcredit_policy          int64\n",
      "purpose               object\n",
      "int_rate             float64\n",
      "installment          float64\n",
      "log_annual_inc       float64\n",
      "dti                  float64\n",
      "fico                   int64\n",
      "days_with_cr_line    float64\n",
      "revol_bal              int64\n",
      "revol_util           float64\n",
      "inq_last_6mths       float64\n",
      "delinq_2yrs          float64\n",
      "pub_rec              float64\n",
      "not_fully_paid         int64\n",
      "dtype: object\n",
      "\n",
      "\u001b[1m\u001b[94mSum of null values in each feature:\n",
      "-----------------------------------\n",
      "\u001b[30mcredit_policy         0\n",
      "purpose               0\n",
      "int_rate              0\n",
      "installment           0\n",
      "log_annual_inc        4\n",
      "dti                   0\n",
      "fico                  0\n",
      "days_with_cr_line    29\n",
      "revol_bal             0\n",
      "revol_util           62\n",
      "inq_last_6mths       29\n",
      "delinq_2yrs          29\n",
      "pub_rec              29\n",
      "not_fully_paid        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>purpose</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>not_fully_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_policy             purpose  int_rate  installment  log_annual_inc  \\\n",
       "0              1  debt_consolidation    0.1189       829.10       11.350407   \n",
       "1              1         credit_card    0.1071       228.22       11.082143   \n",
       "2              1  debt_consolidation    0.1357       366.86       10.373491   \n",
       "3              1  debt_consolidation    0.1008       162.34       11.350407   \n",
       "4              1         credit_card    0.1426       102.92       11.299732   \n",
       "\n",
       "     dti  fico  days_with_cr_line  revol_bal  revol_util  inq_last_6mths  \\\n",
       "0  19.48   737        5639.958333      28854        52.1             0.0   \n",
       "1  14.29   707        2760.000000      33623        76.7             0.0   \n",
       "2  11.63   682        4710.000000       3511        25.6             1.0   \n",
       "3   8.10   712        2699.958333      33667        73.2             1.0   \n",
       "4  14.97   667        4066.000000       4740        39.5             0.0   \n",
       "\n",
       "   delinq_2yrs  pub_rec  not_fully_paid  \n",
       "0          0.0      0.0               0  \n",
       "1          0.0      0.0               0  \n",
       "2          0.0      0.0               0  \n",
       "3          0.0      0.0               0  \n",
       "4          1.0      0.0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../data/loans.csv\")\n",
    "\n",
    "# Check both the datatypes and if there is missing values\n",
    "print(f\"\\033[1m\\033[94mData types:\\n{11 * '-'}\")\n",
    "print(f\"\\033[30m{df.dtypes}\\n\")\n",
    "print(f\"\\033[1m\\033[94mSum of null values in each feature:\\n{35 * '-'}\")\n",
    "print(f\"\\033[30m{df.isnull().sum()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples = 1533\n",
      "Negative examples = 8045\n",
      "Proportion of positive to negative examples = 19.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125417940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get number of positve and negative examples\n",
    "pos = df[df[\"not_fully_paid\"] == 1].shape[0]\n",
    "neg = df[df[\"not_fully_paid\"] == 0].shape[0]\n",
    "print(f\"Positive examples = {pos}\")\n",
    "print(f\"Negative examples = {neg}\")\n",
    "print(f\"Proportion of positive to negative examples = {(pos / neg) * 100:.2f}%\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(df[\"not_fully_paid\"])\n",
    "plt.xticks((0, 1), [\"Paid fully\", \"Not paid fully\"])\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class counts\", y=1, fontdict={\"fontsize\": 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have only one categorical feature (\"purpose\"). Also, six features have missing values (no missing values in labels feature). Moreover, the data set is pretty imbalanced as expected where positive examples (\"not paid fully\") are only 19%. We'll explain in the next section how to handle all of them after giving an overview of ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2 style=\"font-family: Georgia; font-size:2em;color:purple; font-style:bold\">\n",
    "Modeling</h2><br>\n",
    "**Ensemble methods** can be defined as combining several different models (base learners) into final model (meta learner) to reduce the generalization error. It relies on the assumption that each model would look at a different aspect of the data which yield to capturing part of the truth. Combining good performing models the were trained independently will capture more of the truth than a single model. Therefore, this would result in more accurate predictions and lower generalization errors.\n",
    "- Almost always ensemble model performance gets improved as we add more models.\n",
    "- Try to combine models that are as much different as possible. This will reduce the correlation between the models that will improve the performance of the ensemble model that will lead to significantly outperform the best model. In the worst case where all models are perfectly correlated, the ensemble would have the same performance as the best model and sometimes even lower if some models are very bad. As a result, pick models that are as good as possible.\n",
    "\n",
    "Diﬀerent ensemble methods construct the ensemble of models in diﬀerent ways. Below are the most common methods:\n",
    "- Averaging the predictions of all models.\n",
    "- Bagging: build different models on different datasets and then take the majority vote from all the models. Given the original dataset, we sample with replacement to get the same size of the original dataset. Therefore, each dataset will include, on average, 2/3 of the original data and the rest 1/3 will be duplicates. Since each model will be built on a different dataset, it can be seen as a different model. It reduces the variances of decision trees by reducing the likelihood of strong features to picked on every split. In other word, it reduces the number of features available at each split from $n$ to $n/2$ or $log(n)$.\n",
    "- Boosting: build models sequentially. That means each model learns from the residuals of the previous model. The output will be all output of each single model weighted by the learning rate ($\\lambda$). It reduces the bias resulted from bagging by learning sequentially from residuals of previous trees (models). \n",
    "- Stacking: Build k models called base learners. Then fit a model to the output of the base learners to predict the final output. We'll explain more in \"Modeling\" section of how it works.\n",
    "\n",
    "Since we'll be using Random Fores (bagging) and Gradient Boosting (boosting) classifiers as base learners in the ensemble model, we'll illustrate only averaging and stacking ensemble methods. Therefore, modeling parts would be consisted of three parts:\n",
    "- Strategies to deal with missing values.\n",
    "- Strategies to deal with imbalanced datasets.\n",
    "- Build Ensemble models.\n",
    "\n",
    "Before going further, the following data preprocessing steps will be applicable to all models:\n",
    "1. Create dummy variables from the feature \"purpose\" since its nominal (not ordinal) categorical variable. It's also a good practice to drop the first one to avoid linear dependency between the resulted features since some algorithms may struggle with this issue.\n",
    "3. Split the data into training set (70%), and test set (30%). Training set will be used to fit the model, and test set will be to evaluate the best model to get an estimation of generalization error. Instead of having validation set to tune hyperparameters and evaluate different models, we'll use 10-folds cross validation because it's more reliable estimate of generalization error.\n",
    "2. Standardize the data. We'll be using `RobustScaler` so that the standarization will be less influenced by the outliers, i.e. more robust. It centers the data around the median and scale it using *interquartile range (IQR)*. This step will be included in the pipelines for each model as a transformer so we will not do it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>not_fully_paid</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_policy  int_rate  installment  log_annual_inc    dti  fico  \\\n",
       "0              1    0.1189       829.10       11.350407  19.48   737   \n",
       "1              1    0.1071       228.22       11.082143  14.29   707   \n",
       "2              1    0.1357       366.86       10.373491  11.63   682   \n",
       "3              1    0.1008       162.34       11.350407   8.10   712   \n",
       "4              1    0.1426       102.92       11.299732  14.97   667   \n",
       "\n",
       "   days_with_cr_line  revol_bal  revol_util  inq_last_6mths  delinq_2yrs  \\\n",
       "0        5639.958333      28854        52.1             0.0          0.0   \n",
       "1        2760.000000      33623        76.7             0.0          0.0   \n",
       "2        4710.000000       3511        25.6             1.0          0.0   \n",
       "3        2699.958333      33667        73.2             1.0          0.0   \n",
       "4        4066.000000       4740        39.5             0.0          1.0   \n",
       "\n",
       "   pub_rec  not_fully_paid  purpose_credit_card  purpose_debt_consolidation  \\\n",
       "0      0.0               0                    0                           1   \n",
       "1      0.0               0                    1                           0   \n",
       "2      0.0               0                    0                           1   \n",
       "3      0.0               0                    0                           1   \n",
       "4      0.0               0                    1                           0   \n",
       "\n",
       "   purpose_educational  purpose_home_improvement  purpose_major_purchase  \\\n",
       "0                    0                         0                       0   \n",
       "1                    0                         0                       0   \n",
       "2                    0                         0                       0   \n",
       "3                    0                         0                       0   \n",
       "4                    0                         0                       0   \n",
       "\n",
       "   purpose_small_business  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables from the feature purpose\n",
    "df = pd.get_dummies(df, columns=[\"purpose\"], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3 style=\"font-family: Georgia; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Strategies to deal with missing value</h3><br>\n",
    "Almost always real world data sets have missing values. This can be due, for example, users didn't fill some part of the forms or some transformations happened while collecting and cleaning the data before they send it to you. Sometimes missing values are informative and weren't generated randomly. Therefore, it's a good practice to add binary features to check if there is missing values in each row for each feature that has missing values. In our case, six features have missing values so we would add six binary features one for each feature. For example, \"log_annual_inc\" feature has missing values, so we would add a feature \"is_log_annual_inc_missing\" that takes the values $\\in \\{0, 1\\}$. Good thing is that the missing values are in the predictors only and not the labels. Below are some of the most common strategies for dealing with missing values:\n",
    "- Simply delete all examples that have any missing values. This is usually done if the missing values are very small compared to the size of the data set and the missing values were random. In other words, the added binary features did improve the model. One disadvantage for this strategy is that the model will throw an error when test data has missing values at prediction.\n",
    "- Impute the missing values using the mean of each feature separately.\n",
    "- Impute the missing values using the median of each feature separately.\n",
    "- Use *Multivariate Imputation by Chained Equations (MICE)*. The main disadvantage of MICE is that we can't use it as a transformer in sklearn pipelines and it requires to use the full data set when imputing the missing values. This means that there will be a risk of data leakage since we're using both training and test sets to impute missing values. The followig steps explain how MICE works:\n",
    "    - First step: impute the missing values using the mean of each feature separatelty.\n",
    "    - Second step: for each feature that has missing values, we take all other features as predictors (including the ones that had missing values) and try to predict the values for this feature using linear regression for example. The predicted values will replace the old values for that feature. We do this for all features that have missing values, i.e. each feature will be used once as a target variable to predict its values and the rest of the time as a predictor to predict other features's values. Therefore, one complete cycle (iteration) will be done once we run the model $k$ times to predict the $k$ features that have missing values. For our data set, each iteration will run the linear regression 6 times to predict the 6 features.\n",
    "    - Thired step: Repeat step 2 until there is not much of change between predictions.\n",
    "- Impute the missing values using K-Nearest Neighbors. We compute distance between all examples (excluding missing values) in the data set and take the average of k-nearest neighbors of each missing value. There's no implementation for it yet in sklearn and it's pretty inefficient to compute it since we'll have to go through all examples to calculate distances. Therefore, we'll skip this strategy in this notebook.\n",
    "\n",
    "To evaluate each strategy, we'll use *Random Forest* classifier with hyperparameters' values guided by [Data-driven Advice for Applying Machine Learning to Bioinformatics Problems](https://arxiv.org/pdf/1708.05070.pdf) as a starting point.\n",
    "\n",
    "Let's first create binary features for missing values and then prepare the data for each strategy discussed above. Next, we'll compute the 10-folds cross validation *AUC* score for all the models using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_annual_inc sum of nans: 4\n",
      "days_with_cr_line sum of nans: 29\n",
      "revol_util sum of nans: 62\n",
      "inq_last_6mths sum of nans: 29\n",
      "delinq_2yrs sum of nans: 29\n",
      "pub_rec sum of nans: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>is_log_annual_inc_missing</th>\n",
       "      <th>is_days_with_cr_line_missing</th>\n",
       "      <th>is_revol_util_missing</th>\n",
       "      <th>is_inq_last_6mths_missing</th>\n",
       "      <th>is_delinq_2yrs_missing</th>\n",
       "      <th>is_pub_rec_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_policy  int_rate  installment  log_annual_inc    dti  fico  \\\n",
       "0              1    0.1189       829.10       11.350407  19.48   737   \n",
       "1              1    0.1071       228.22       11.082143  14.29   707   \n",
       "2              1    0.1357       366.86       10.373491  11.63   682   \n",
       "3              1    0.1008       162.34       11.350407   8.10   712   \n",
       "4              1    0.1426       102.92       11.299732  14.97   667   \n",
       "\n",
       "   days_with_cr_line  revol_bal  revol_util  inq_last_6mths  \\\n",
       "0        5639.958333      28854        52.1             0.0   \n",
       "1        2760.000000      33623        76.7             0.0   \n",
       "2        4710.000000       3511        25.6             1.0   \n",
       "3        2699.958333      33667        73.2             1.0   \n",
       "4        4066.000000       4740        39.5             0.0   \n",
       "\n",
       "          ...          purpose_educational  purpose_home_improvement  \\\n",
       "0         ...                            0                         0   \n",
       "1         ...                            0                         0   \n",
       "2         ...                            0                         0   \n",
       "3         ...                            0                         0   \n",
       "4         ...                            0                         0   \n",
       "\n",
       "   purpose_major_purchase  purpose_small_business  is_log_annual_inc_missing  \\\n",
       "0                       0                       0                          0   \n",
       "1                       0                       0                          0   \n",
       "2                       0                       0                          0   \n",
       "3                       0                       0                          0   \n",
       "4                       0                       0                          0   \n",
       "\n",
       "   is_days_with_cr_line_missing  is_revol_util_missing  \\\n",
       "0                             0                      0   \n",
       "1                             0                      0   \n",
       "2                             0                      0   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   is_inq_last_6mths_missing  is_delinq_2yrs_missing  is_pub_rec_missing  \n",
       "0                          0                       0                   0  \n",
       "1                          0                       0                   0  \n",
       "2                          0                       0                   0  \n",
       "3                          0                       0                   0  \n",
       "4                          0                       0                   0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary features to check if the example is has missing values for all features that have missing values\n",
    "for feature in df.columns:\n",
    "    if np.any(np.isnan(df[feature])):\n",
    "        df[\"is_\" + feature + \"_missing\"] = np.isnan(df[feature]) * 1\n",
    "        print(f\"{feature} sum of nans: {np.isnan(df[feature]).sum()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shapes: ((7662, 24), (1916, 24))\n",
      "After dropping NAs: ((7611, 18), (1905, 18))\n",
      "MICE data shapes: ((7662, 24), (1916, 24))\n"
     ]
    }
   ],
   "source": [
    "# Original Data\n",
    "X = df.loc[:, df.columns != \"not_fully_paid\"].values\n",
    "y = df.loc[:, df.columns == \"not_fully_paid\"].values.flatten()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\n",
    "print(f\"Original data shapes: {X_train.shape, X_test.shape}\")\n",
    "\n",
    "# Drop NA and remove binary columns\n",
    "train_indices_na = np.max(np.isnan(X_train), axis=1)\n",
    "test_indices_na = np.max(np.isnan(X_test), axis=1)\n",
    "X_train_dropna, y_train_dropna = X_train[~train_indices_na, :][:, :-6], y_train[~train_indices_na]\n",
    "X_test_dropna, y_test_dropna = X_test[~test_indices_na, :][:, :-6], y_test[~test_indices_na]\n",
    "print(f\"After dropping NAs: {X_train_dropna.shape, X_test_dropna.shape}\")\n",
    "\n",
    "# MICE data\n",
    "mice = fancyimpute.MICE(verbose=0)\n",
    "X_mice = mice.complete(X)\n",
    "X_train_mice, X_test_mice, y_train_mice, y_test_mice = train_test_split(\n",
    "    X_mice, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\n",
    "print(f\"MICE data shapes: {X_train_mice.shape, X_test_mice.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mBaseline model's average AUC: 0.653\n",
      "\u001b[1m\u001b[94mMean imputation model's average AUC: 0.649\n",
      "\u001b[1m\u001b[94mMedian imputation model's average AUC: 0.653\n",
      "\u001b[1m\u001b[94mMICE imputation model's average AUC: 0.649\n"
     ]
    }
   ],
   "source": [
    "# Build random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_features=0.25,\n",
    "                                criterion=\"entropy\",\n",
    "                                class_weight=\"balanced\")\n",
    "# Build base line model -- Drop NA's\n",
    "pip_baseline = make_pipeline(RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_baseline,\n",
    "                         X_train_dropna, y_train_dropna,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mBaseline model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with mean imputation\n",
    "pip_impute_mean = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                                RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_impute_mean,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mMean imputation model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with median imputation\n",
    "pip_impute_median = make_pipeline(Imputer(strategy=\"median\"),\n",
    "                                  RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_impute_median,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mMedian imputation model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model using MICE imputation\n",
    "pip_impute_mice = make_pipeline(RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_impute_mice,\n",
    "                         X_train_mice, y_train_mice,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mMICE imputation model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125a8af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit RF to plot feature importances\n",
    "rf_clf.fit(RobustScaler().fit_transform(Imputer(strategy=\"median\").fit_transform(X_train)), y_train)\n",
    "\n",
    "# Plot features importance\n",
    "importances = rf_clf.feature_importances_\n",
    "indices = np.argsort(rf_clf.feature_importances_)[::-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, 25), importances[indices], align=\"center\")\n",
    "plt.xticks(range(1, 25), df.columns[df.columns != \"not_fully_paid\"][indices], rotation=90)\n",
    "plt.title(\"Feature Importance\", {\"fontsize\": 16});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guided by the 10-fold cross validation *AUC* scores, it looks like all strategies have comparable results and missing values were generated randomly. Also, the added six binary features showed no importance when plotting feature importances from *Random Forest* classifier. Therefore, it's safe to drop those features and use *Median Imputation* method as a transformer later on in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop generated binary features\n",
    "X_train = X_train[:, :-6]\n",
    "X_test = X_test[:, :-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3 style=\"font-family: Georgia; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Strategies to deal with imbalanced data</h3><br>\n",
    "Classification problems in most real world applications have imbalanced data sets. In other words, the positive examples (minority class) are a lot less than negative examples (majority class). We can see that in spam detection, ads click, loan approvals, etc. In our example, the positive examples (people who didn't fully paid) were only 19% from the total examples. Therefore, accuracy is no longer a good measure of performance for different models because we simply predict all examples to belong to the negative class, we achieve 81% accuracy. Better metrics for imbalanced data sets are *AUC* (area under the ROC curve) and f1-score. However, that's not enough because class imbalance influences a learning algorithm during training by making the decision rule biased towards the majority class by implicitly learns a model that optimizes the predictions based on the majority class in the dataset. As a result, we'll explore different methods to overcome class imbalance problem.\n",
    "- Under-sample: under-sample the majority class w/o replacement by making the number of positive and negative examples equal. One of the drawbacks of under-sampling is that it ignores a good portion of training data that has valuable information. In our example, it would loose around 6500 examples. However, it's very fast to train.\n",
    "- Over-sample: over-sample the minority class w/o replacement by making the number of positive and negative examples equal. We'll add around 6500 samples from the training data set with this strategy. It's a lot more computationally expensive than under-sampling. Also, it's more prune to overfitting due repeated examples.\n",
    "- Easy Ensemble: sample several subsets from the majority class, build a classifier on top of each sampled data, and combine the output of all classifiers. More details can be found [here](http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tsmcb09.pdf)\n",
    "- Synthetic minority over-sampling technique (SMOTE): It over-samples the minority class but using synthesized examples. It operates on feature space not the data space. Here how it works:\n",
    "    - Compute the k-nearest neighbors for all minority samples.\n",
    "    - Randomly choose number between 1-k.\n",
    "    - For each feature:\n",
    "        - Compute the difference between minority sample and its randomly chosen neighbor (from previous step).\n",
    "        - Multiple the difference by random number between 0 and 1.\n",
    "        - Add the obtained feature to the synthesized sample attributes\n",
    "    - Repeat the above until we get the number of synthesized samples needed. More information can be found [here](https://www.jair.org/media/953/live-953-2037-jair.pdf).\n",
    "In most applications, misclassifying the minority class (false negative) is a lot more expensive than misclassifying the majority class (false positive). In the context of lending, loosing money by lending to a risky borrower who is more likely to not fully pay the loan back is a lot more costly than missing the opportunity of lending to trust-worthy borrower (less risky).\n",
    "\n",
    "There are other methods such as `EditedNearestNeighbors` and `CondensedNearestNeighbors` that we will not cover in this notebook and are rarely used in practice. We'll evaluate all the above methods plus the original model without resampling as a baseline model using the same *Random Forest* classifier we used in the missing values section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mOriginal model's average AUC: 0.653\n",
      "\u001b[1m\u001b[94mUnder-sampled model's average AUC: 0.648\n",
      "\u001b[1m\u001b[94mOver-sampled model's average AUC: 0.650\n",
      "\u001b[1m\u001b[94mEasyEnsemble model's average AUC: 0.666\n",
      "\u001b[1m\u001b[94mSMOTE model's average AUC: 0.643\n"
     ]
    }
   ],
   "source": [
    "# Build random forest classifier (same config)\n",
    "rf_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_features=0.25,\n",
    "                                criterion=\"entropy\",\n",
    "                                class_weight=\"balanced\")\n",
    "\n",
    "# Build model with no sampling\n",
    "pip_orig = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                         RobustScaler(),\n",
    "                         rf_clf)\n",
    "scores = cross_val_score(pip_orig,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mOriginal model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with undersampling\n",
    "pip_undersample = imb_make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                                    RobustScaler(),\n",
    "                                    RandomUnderSampler(), rf_clf)\n",
    "scores = cross_val_score(pip_undersample,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mUnder-sampled model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with oversampling\n",
    "pip_oversample = imb_make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                                    RobustScaler(),\n",
    "                                    RandomOverSampler(), rf_clf)\n",
    "scores = cross_val_score(pip_oversample,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mOver-sampled model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with EasyEnsemble\n",
    "resampled_rf = BalancedBaggingClassifier(base_estimator=RandomForestClassifier(),\n",
    "                                         n_estimators=100, random_state=123)\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(), resampled_rf)\n",
    "                             \n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mEasyEnsemble model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with SMOTE\n",
    "pip_smote = imb_make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(),\n",
    "                              SMOTE(), rf_clf)\n",
    "scores = cross_val_score(pip_smote,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mSMOTE model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyEnsemble method has the highest 10-folds CV with average AUC = 0.666. Therefore, we'll use it when building ensemble models in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3 style=\"font-family: Georgia; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Build Ensemble methods</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9075 candidates, totalling 45375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 492 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 868 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1387 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2173 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2815 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3891 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4986 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6223 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7669 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9283 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 10865 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12908 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14726 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 16832 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 18960 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 21257 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 23548 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 26175 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 29091 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done 32229 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 35463 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 38715 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 42109 tasks      | elapsed: 34.3min\n",
      "[Parallel(n_jobs=-1)]: Done 45375 out of 45375 | elapsed: 37.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('randomundersampler', RandomUnderSampler(random_state=None, ratio='auto', replac...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'xgbclassifier__n_estimators': [10, 50, 100, 300, 500], 'xgbclassifier__learning_rate': [0.001, 0.01, 0.1], 'xgbclassifier__gamma': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ]), 'xgbclassifier__max_depth': [1, 2, 3, 4, 5], 'xgbclassifier__subsample': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip_xgb = imb_make_pipeline(\n",
    "    Imputer(strategy=\"median\"),\n",
    "    RobustScaler(),\n",
    "    RandomUnderSampler(),\n",
    "    xgb.XGBClassifier()\n",
    "    )\n",
    "\n",
    "hyperparam_grid = {\n",
    "    \"xgbclassifier__n_estimators\": [10, 50, 100, 300, 500],\n",
    "    \"xgbclassifier__learning_rate\": [0.001, 0.01, 0.1],\n",
    "    \"xgbclassifier__gamma\": np.arange(0., 0.51, 0.05),\n",
    "    \"xgbclassifier__max_depth\": [1, 2, 3, 4, 5],\n",
    "    \"xgbclassifier__subsample\": np.arange(0.0, 1.01, 0.1)\n",
    "                  }\n",
    "\n",
    "gs_xgb = GridSearchCV(pip_xgb,\n",
    "                      param_grid=hyperparam_grid,\n",
    "                      scoring=\"roc_auc\",\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1)\n",
    "\n",
    "gs_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6675178812914019,\n",
       " {'xgbclassifier__gamma': 0.5,\n",
       "  'xgbclassifier__learning_rate': 0.01,\n",
       "  'xgbclassifier__max_depth': 3,\n",
       "  'xgbclassifier__n_estimators': 500,\n",
       "  'xgbclassifier__subsample': 0.30000000000000004})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb.best_score_, gs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e06783801637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m scores = cross_val_score(pip_resampled,\n\u001b[1;32m     18\u001b[0m                          \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                          scoring=\"roc_auc\", cv=10)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\033[1m\\033[94mXGB average AUC: {scores.mean():.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/imblearn/ensemble/classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# RandomUnderSampler is not supporting sample_weight. We need to pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 375\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Draw samples, using a mask, and then fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build model with EasyEnsemble\n",
    "resampled_rf = BalancedBaggingClassifier(\n",
    "    base_estimator=xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=100,\n",
    "        max_depth=3,\n",
    "        gamma=0.5,\n",
    "        subsample=0.3,\n",
    "        random_state=123),\n",
    "    n_estimators=100,\n",
    "    random_state=123)\n",
    "\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"median\"),\n",
    "                              RobustScaler(), resampled_rf)\n",
    "\n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mXGB average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid={\"kneighborsclassifier__n_neighbors\": range(1, 11),\n",
    "                 \"kneighbors__weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "resampled_knn = BalancedBaggingClassifier(\n",
    "    base_estimator=KNeighborsClassifier(),\n",
    "    n_estimators=100,\n",
    "    random_state=123)\n",
    "\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"median\"),\n",
    "                              RobustScaler(), resampled_knn)\n",
    "\n",
    "gs_knn = GridSearchCV(pip_resampled,\n",
    "                      param_grid=hyperparam_grid,\n",
    "                      scoring=\"roc_auc\",\n",
    "                      cv=10,\n",
    "                      n_jobs=-1)\n",
    "gs_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4bdff28d255e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                       n_jobs=-1)\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgs_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparam_grid={\"balancedbaggingclassifier__base_estimator__n_neighbors\": range(1, 11),\n",
    "                 \"balancedbaggingclassifier__base_estimator__weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "resampled_knn = BalancedBaggingClassifier(\n",
    "    base_estimator=KNeighborsClassifier(),\n",
    "    n_estimators=100,\n",
    "    random_state=123)\n",
    "\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"median\"),\n",
    "                              RobustScaler(), resampled_knn)\n",
    "\n",
    "gs_knn = GridSearchCV(pip_resampled,\n",
    "                      param_grid=hyperparam_grid,\n",
    "                      scoring=\"roc_auc\",\n",
    "                      cv=10,\n",
    "                      n_jobs=-1)\n",
    "gs_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mXGB average AUC: 0.665\n"
     ]
    }
   ],
   "source": [
    "# Build model with EasyEnsemble\n",
    "resampled_rf = BalancedBaggingClassifier(\n",
    "    base_estimator=xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        max_depth=1,\n",
    "        random_state=123),\n",
    "    n_estimators=100,\n",
    "    random_state=123)\n",
    "\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"median\"),\n",
    "                              RobustScaler(), resampled_rf)\n",
    "\n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mXGB average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mLogistic regression model's average AUC: 0.672\n"
     ]
    }
   ],
   "source": [
    "# Build model with Easy Ensemble\n",
    "resampled_lr = BalancedBaggingClassifier(\n",
    "    base_estimator=LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        C=1.5,\n",
    "        fit_intercept=True),\n",
    "    n_estimators=100, random_state=123)\n",
    "\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(), resampled_lr)\n",
    "                             \n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mLogistic regression model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mSVM model's average AUC: 0.671\n"
     ]
    }
   ],
   "source": [
    "# Build model with Easy Ensemble\n",
    "resampled_svc = BalancedBaggingClassifier(\n",
    "    base_estimator=SVC(gamma=0.1,\n",
    "        C=0.01,\n",
    "        kernel=\"poly\",\n",
    "        degree=3,\n",
    "        coef0=10.0),\n",
    "    n_estimators=100, random_state=123)\n",
    "\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(), resampled_svc)\n",
    "                             \n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mSVM model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               2432      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,073\n",
      "Trainable params: 19,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = models.Sequential()\n",
    "nn_model.add(layers.Dense(128, activation=\"relu\", input_shape=(18,)))\n",
    "nn_model.add(layers.Drop)\n",
    "nn_model.add(layers.Dense(128, activation=\"relu\"))\n",
    "nn_model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "nn_model.summary()\n",
    "\n",
    "nn_model.compile(optimizer=optimizers.SGD(lr=0.01),\n",
    "                 loss=\"binary_crossentropy\",\n",
    "                 metrics=[\"acc\"])\n",
    "history = nn_model.fit(X_train, y_train,\n",
    "                     batch_size=64,\n",
    "                     epochs=100,\n",
    "                     validation_data=[X_valid, y_valid], class_weight={0:1, 1: 5})\n",
    "roc_auc_score(y_valid, nn_model.predict_proba(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mLogistic regression model's average AUC: 0.673\n"
     ]
    }
   ],
   "source": [
    "# Build model with Easy Ensemble\n",
    "resampled_lr = BalancedBaggingClassifier(base_estimator=LogisticRegression(penalty=\"l1\",\n",
    "                                                                           C=1.5,\n",
    "                                                                           fit_intercept=True),\n",
    "                                         n_estimators=100, random_state=123)\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(), resampled_lr)\n",
    "                             \n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mLogistic regression model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mSVM model's average AUC: 0.671\n"
     ]
    }
   ],
   "source": [
    "# Build model with Easy Ensemble\n",
    "resampled_svc = BalancedBaggingClassifier(base_estimator=SVC(gamma=0.1,\n",
    "                                                            C=0.01,\n",
    "                                                            kernel=\"poly\",\n",
    "                                                            degree=3,\n",
    "                                                            coef0=10.0),\n",
    "                                         n_estimators=100, random_state=123)\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(), resampled_svc)\n",
    "                             \n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mSVM model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.47\n"
     ]
    }
   ],
   "source": [
    "pip_rf = make_pipeline(RandomForestClassifier(class_weight=\"balanced\",\n",
    "                                              random_state=123))\n",
    "hyperparam_grid = {\n",
    "        \"randomforestclassifier__n_estimators\": [10, 50, 100, 500],\n",
    "        \"randomforestclassifier__max_features\": [\"sqrt\", \"log2\", 0.4, 0.5],\n",
    "        \"randomforestclassifier__min_samples_leaf\": [1, 3, 5],\n",
    "        \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "gs_rf = GridSearchCV(pip_rf,\n",
    "                     hyperparam_grid,\n",
    "                     scoring=\"f1\",\n",
    "                     cv=10,\n",
    "                     n_jobs=-1)\n",
    "gs_rf.fit(X_train_u, y_train_u)\n",
    "print(f\"{gs_rf.best_score_ * 100:.2f}\")\n",
    "\n",
    "pip_logmod = make_pipeline(LogisticRegression(class_weight=\"balanced\"))\n",
    "\n",
    "hyperparam_range = np.arange(0.5, 20.1, 0.5)\n",
    "\n",
    "hyperparam_grid = {\"logisticregression__penalty\": [\"l1\", \"l2\"],\n",
    "                   \"logisticregression__C\":  hyperparam_range,\n",
    "                   \"logisticregression__fit_intercept\": [True, False]\n",
    "                   }\n",
    "\n",
    "gs_logmodel = GridSearchCV(pip_logmod,\n",
    "                           hyperparam_grid,\n",
    "                           scoring=\"f1\",\n",
    "                           cv=10,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "gs_logmodel.fit(X_train_u, y_train_u)\n",
    "print(f\"{gs_logmodel.best_score_ * 100:.2f}\")\n",
    "\n",
    "pip_xgb = make_pipeline(xgb.XGBClassifier())\n",
    "\n",
    "hyperparam_grid = {\n",
    "    \"xgbclassifier__n_estimators\": [10, 50, 100, 500],\n",
    "    \"xgbclassifier__learning_rate\": [0.01, 0.1, 0.5, 1.0, 10.0, 50.0, 100.0],\n",
    "    \"xgbclassifier__gamma\": np.arange(0., 0.51, 0.05),\n",
    "    \"xgbclassifier__max_depth\": [1, 2, 3, 4, 5, 10, 20, 50],\n",
    "    \"xgbclassifier__subsample\": np.arange(0.0, 1.01, 0.1)\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(pip_xgb,\n",
    "                      hyperparam_grid,\n",
    "                      scoring=\"f1\",\n",
    "                      cv=2,\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1)\n",
    "\n",
    "gs_xgb.fit(X_train_u, y_train_u)\n",
    "print(f\"{gs_xgb.best_score_ * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    \"\"\"Implement ensemble model\"\"\"\n",
    "    def __init__(self, base_learners, X_train, y_train):\n",
    "        \"\"\"\n",
    "        base_learners: dict\n",
    "            base learners sklearn.estimator\n",
    "        \"\"\"\n",
    "        self.base_learners = base_learners\n",
    "        self.meta_learner = RandomForestClassifier(n_estimators=500,\n",
    "                                                   max_features=0.25,\n",
    "                                                   criterion=\"entropy\")\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_train_base, self.y_train_base, self.X_train_pred, self.y_train_pred = split_train_data()\n",
    "        \n",
    "        def split_train_data(self):\n",
    "            \"\"\"Split the training data 50/50 into training for base learners and training\n",
    "               for meta learner.\n",
    "            \"\"\"\n",
    "            X_train_base, X_train_pred, y_train_base, y_train_pred = train_test_split(\n",
    "                self.X_train, self.y_train, test_size=0.5, random_state=123, stratify=y)\n",
    "            \n",
    "            return X_train_base, y_train_base, X_train_pred, y_train_pred\n",
    "        \n",
    "        def train_base_learner(self):\n",
    "            \"\"\"Train base learners\"\"\"\n",
    "            for name, classifier in self.base_learners.items():\n",
    "                print(f\"\\033[1m\\033[94mTraining {name} classifier...\")\n",
    "                classifier.fit(X_train, y_train)\n",
    "                print(f\"\\033[1m\\033[92mDone\")\n",
    "                \n",
    "        def base_learners_predict(self):\n",
    "            self.prob_matrix = np.zeros((self.X_train_pred.shape[0], len(self.base_learners)))\n",
    "            self.prob_matrix = pd.DataFrame(prob_matrix)\n",
    "            self.prob_matrix.columns = base_learners.keys()\n",
    "\n",
    "            for name, classifier in self.base_learners.items():\n",
    "                self.prob_matrix.loc[:, name] = classifier.predict_proba(self.X_train_pred)[:, 1]\n",
    "\n",
    "            return self.prob_matrix\n",
    "        \n",
    "        def train_meta_learner(self)\n",
    "            print(f\"\\033[1m\\033[94mTraining starts...\")\n",
    "            meta_learner.fit(self.prob_matrix, y_train_pred)\n",
    "            print(f\"\\033[1m\\033[92mDone\")\n",
    "            \n",
    "        def meta_learner_predict(self, X_test):\n",
    "            base_learner_pred = \n",
    "            return meta_learner.predict_proba(base_learner_probs)[:, 1]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define base learners\n",
    "base_learners = {\"random_forest\": RandomForestClassifier(n_estimators=500,\n",
    "                                                         max_features=0.25,\n",
    "                                                         criterion=\"entropy\"),\n",
    "                 \"logistic_regression\": LogisticRegression(C=1.5,\n",
    "                                                           penalty=\"l1\",\n",
    "                                                           fit_intercept=True),\n",
    "#                  \"extra_tree\": ExtraTreesClassifier(n_estimators=1000,\n",
    "#                                                     max_features=\"log2\",\n",
    "#                                                     criterion=\"entropy\"),\n",
    "#                  \"gradient_boosting\": GradientBoostingClassifier(loss=\"deviance\",\n",
    "#                                                                  learning_rate=0.1,\n",
    "#                                                                  n_estimators=500,\n",
    "#                                                                  max_depth=3,\n",
    "#                                                                  max_features=\"log2\"),\n",
    "                 \"svc\": SVC(C=0.01, gamma=0.1, kernel=\"poly\", degree=3, coef0=10,\n",
    "                            probability=True)}\n",
    "\n",
    "# Define meta learner\n",
    "# meta_learner = RandomForestClassifier(n_estimators=500,\n",
    "#                                       max_features=0.25,\n",
    "#                                       criterion=\"entropy\")\n",
    "# meta_learner = LinearRegression()\n",
    "meta_learner = GradientBoostingClassifier(loss=\"deviance\",\n",
    "                                         learning_rate=0.01,\n",
    "                                         n_estimators=500,\n",
    "                                         max_depth=3,\n",
    "                                         max_features=\"log2\")\n",
    "meta_learner = LogisticRegression(C=1.5,\n",
    "                                   penalty=\"l1\",\n",
    "                                   fit_intercept=True)\n",
    "\n",
    "def train_base_learners(base_learners, X_train_base, y_train_base):\n",
    "    print(\"Training base learners starts\")\n",
    "    print(20 * \"---\")\n",
    "    for name, classifier in base_learners.items():\n",
    "        print(f\"\\033[1m\\033[94mTraining {name} classifier...\")\n",
    "        classifier.fit(X_train_base, y_train_base)\n",
    "        print(f\"\\033[1m\\033[92mDone\")\n",
    "    print(20 * \"---\")\n",
    "\n",
    "\n",
    "def predict_base_learners(base_learners, X_train_pred):\n",
    "    probs_matrix = np.zeros((X_train_pred.shape[0], len(base_learners)))\n",
    "    probs_matrix = pd.DataFrame(probs_matrix)\n",
    "    probs_matrix.columns = base_learners.keys()\n",
    "\n",
    "    for name, classifier in base_learners.items():\n",
    "        probs_matrix.loc[:, name] = classifier.predict_proba(X_train_pred)[:, 1]\n",
    "\n",
    "    return probs_matrix\n",
    "\n",
    "\n",
    "\n",
    "def train_meta_learner(meta_learner, base_learners_probs, y_train_pred):\n",
    "    print(f\"\\033[1m\\033[94mTraining meta learner starts...\")\n",
    "    meta_learner.fit(base_learners_probs, y_train_pred)\n",
    "    print(f\"\\033[1m\\033[92mDone\")\n",
    "    print(20 * \"---\")\n",
    "    \n",
    "\n",
    "def predict_meta_learner(meta_learner, base_learner_probs, X_test):\n",
    "    return meta_learner.predict_proba(base_learner_probs)[:, 1]\n",
    "#     return meta_learner.predict(base_learner_probs)\n",
    "\n",
    "\n",
    "def ensemble_avg(probs_matrix):\n",
    "    return probs_matrix.mean(axis=1)\n",
    "\n",
    "\n",
    "# Define ensemble weighing method\n",
    "def plot_ensemble_roc(base_learners, meta_learner, X_train, y_train, X_test, y_test):\n",
    "   # Split the data 50/50 into training for base learners and training for meta learner\n",
    "    X_train_base, X_train_pred, y_train_base, y_train_pred = train_test_split(\n",
    "        X_train_u, y_train_u, test_size=0.4, random_state=123, stratify=y_train_u) \n",
    "    \n",
    "    # Train both base learners and meta learner\n",
    "    # Train base learners\n",
    "    train_base_learners(base_learners, X_train_base, y_train_base)\n",
    "    \n",
    "    # Predict probs matrix\n",
    "    base_probs = predict_base_learners(base_learners, X_train_pred)\n",
    "    \n",
    "    # Train meta learner\n",
    "    train_meta_learner(meta_learner, base_probs, y_train_pred)\n",
    "    \n",
    "    # Predict test examples\n",
    "    # Predict test probs\n",
    "    base_probs_test = predict_base_learners(base_learners, X_test)\n",
    "    \n",
    "    # Predict final output using meta learner estimator\n",
    "    meta_probs_test = predict_meta_learner(meta_learner, base_probs_test, X_test)\n",
    "    \n",
    "    # Avergae base learners\n",
    "    avg_probs_test = ensemble_avg(base_probs_test)\n",
    "    \n",
    "#     results = {}\n",
    "    \n",
    "#     for learner in estimators.keys():\n",
    "#         # Compute tpr, fpr, auc and confusion matrix\n",
    "#         fpr, tpr, thresholds = roc_curve(y, estimators[estimator].predict_proba(X)[:, 1])\n",
    "#         auc = roc_auc_score(y, estimators[estimator].predict_proba(X)[:, 1])\n",
    "\n",
    "#         # Plot ROC curce\n",
    "#         plt.plot(fpr, tpr, label=\"{}: auc = {:.3f}\".format(estimator, auc))\n",
    "#         plt.title(\"ROC curve\", y=1, fontdict={\"fontsize\": 20})\n",
    "#         plt.legend(loc=\"lower right\", fontsize=\"medium\")\n",
    "    \n",
    "#     plt.plot([0, 1], [0, 1], \"--\")\n",
    "#     plt.xlabel(\"False positive rate\", fontdict={\"fontsize\": 16})\n",
    "#     plt.ylabel(\"True positive rate\", fontdict={\"fontsize\": 16});\n",
    "    return base_probs_test, avg_probs_test, meta_probs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d67f53be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7eee32e10>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlens.visualization import corrmat\n",
    "corrmat(b.corr(), inflate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2 style=\"font-family: Georgia; font-size:2em;color:purple; font-style:bold\">\n",
    "Conclusion</h2><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
