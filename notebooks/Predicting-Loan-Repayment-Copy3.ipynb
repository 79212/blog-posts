{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: Georgia; font-size:3em;color:#2462C0; font-style:bold\">\n",
    "Predicting Loan Repayment</h1><br>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/Loans-borrow-repay.jpg\"; style=\"height: 400px; width: 800px\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2 style=\"font-family: Georgia; font-size:2em;color:purple; font-style:bold\">\n",
    "Introduction</h2><br>\n",
    "The two most critical questions in the lending industry are: 1) How risky is the borrower? 2) Given the borrower's risk, should we lend him? The answer to the first question determines the interest rate the borrower would have. Interest rate measures among other things (such as time value of money) the riskness of the borrower. The riskier the borrower, the higher the interest rate. With interest rate in mind, we can then determine if the borrower is eligible for the loan.\n",
    "\n",
    "Investors (lenders) provide loans to borrowers in exchange for the promise of repayment with interest. That means the lender only makes profit (interest) if the borrower pays off the loan. However, if he doesn't repay the loan, then the lender loses money.\n",
    "\n",
    "We'll be using publicly available data from [LendingClub.com](https://www.LendingClub.com). The data covers the 9,578 loans funded by the platform between May 2007 and February 2010. The interest rate is provided to us for each borrower. Therefore, so we'll address the second question indirectly by trying to predict if the borrower will repay the loan by its mature date or not. Through this excerise we'll illustrate three modeling concepts:\n",
    "- What to do with missing values.\n",
    "- Techniques used with imbalanced classification problems.\n",
    "- Illustrate how to build an ensemble model that is built on top of other models (stacking), which most likely gives us a boost in performance.\n",
    "\n",
    "Below is a short description of each feature in the data set:\n",
    "- **credit_policy**: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n",
    "- **purpose**: The purpose of the loan such as: credit_card, debt_consolidation, etc.\n",
    "- **int_rate**: The interest rate of the loan (proportion).\n",
    "- **installment**: The monthly installments (\\$) owed by the borrower if the loan is funded.\n",
    "- **log_annual_inc**: The natural log of the annual income of the borrower.\n",
    "- **dti**: The debt-to-income ratio of the borrower.\n",
    "- **fico**: The FICO credit score of the borrower.\n",
    "- **days_with_cr_line**: The number of days the borrower has had a credit line.\n",
    "- **revol_bal**: The borrower's revolving balance.\n",
    "- **revol_util**: The borrower's revolving line utilization rate.\n",
    "- **inq_last_6mths**: The borrower's number of inquiries by creditors in the last 6 months.\n",
    "- **delinq_2yrs**: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n",
    "- **pub_rec**: The borrower's number of derogatory public records.\n",
    "- **not_fully_paid**: indicates whether the loan was not paid back in full (the borrower either defaulted or the borrower was deemed unlikely to pay it back).\n",
    "\n",
    "Let's load the data and check:\n",
    "- Data types of each feature\n",
    "- If we have missing values\n",
    "- If we have imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import fancyimpute\n",
    "from imblearn.pipeline import make_pipeline as imb_make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, EasyEnsemble\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import Imputer, RobustScaler, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix,\n",
    "                             accuracy_score, roc_curve,\n",
    "                             precision_recall_curve, f1_score)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "from keras import models, layers, optimizers\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from scripts.plot_roc import plot_roc_and_pr_curves\n",
    "os.chdir(\"notebooks/\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mData types:\n",
      "-----------\n",
      "\u001b[30mcredit_policy          int64\n",
      "purpose               object\n",
      "int_rate             float64\n",
      "installment          float64\n",
      "log_annual_inc       float64\n",
      "dti                  float64\n",
      "fico                   int64\n",
      "days_with_cr_line    float64\n",
      "revol_bal              int64\n",
      "revol_util           float64\n",
      "inq_last_6mths       float64\n",
      "delinq_2yrs          float64\n",
      "pub_rec              float64\n",
      "not_fully_paid         int64\n",
      "dtype: object\n",
      "\n",
      "\u001b[1m\u001b[94mSum of null values in each feature:\n",
      "-----------------------------------\n",
      "\u001b[30mcredit_policy         0\n",
      "purpose               0\n",
      "int_rate              0\n",
      "installment           0\n",
      "log_annual_inc        4\n",
      "dti                   0\n",
      "fico                  0\n",
      "days_with_cr_line    29\n",
      "revol_bal             0\n",
      "revol_util           62\n",
      "inq_last_6mths       29\n",
      "delinq_2yrs          29\n",
      "pub_rec              29\n",
      "not_fully_paid        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>purpose</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>not_fully_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_policy             purpose  int_rate  installment  log_annual_inc  \\\n",
       "0              1  debt_consolidation    0.1189       829.10       11.350407   \n",
       "1              1         credit_card    0.1071       228.22       11.082143   \n",
       "2              1  debt_consolidation    0.1357       366.86       10.373491   \n",
       "3              1  debt_consolidation    0.1008       162.34       11.350407   \n",
       "4              1         credit_card    0.1426       102.92       11.299732   \n",
       "\n",
       "     dti  fico  days_with_cr_line  revol_bal  revol_util  inq_last_6mths  \\\n",
       "0  19.48   737        5639.958333      28854        52.1             0.0   \n",
       "1  14.29   707        2760.000000      33623        76.7             0.0   \n",
       "2  11.63   682        4710.000000       3511        25.6             1.0   \n",
       "3   8.10   712        2699.958333      33667        73.2             1.0   \n",
       "4  14.97   667        4066.000000       4740        39.5             0.0   \n",
       "\n",
       "   delinq_2yrs  pub_rec  not_fully_paid  \n",
       "0          0.0      0.0               0  \n",
       "1          0.0      0.0               0  \n",
       "2          0.0      0.0               0  \n",
       "3          0.0      0.0               0  \n",
       "4          1.0      0.0               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../data/loans.csv\")\n",
    "\n",
    "# Check both the datatypes and if there is missing values\n",
    "print(f\"\\033[1m\\033[94mData types:\\n{11 * '-'}\")\n",
    "print(f\"\\033[30m{df.dtypes}\\n\")\n",
    "print(f\"\\033[1m\\033[94mSum of null values in each feature:\\n{35 * '-'}\")\n",
    "print(f\"\\033[30m{df.isnull().sum()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples = 1533\n",
      "Negative examples = 8045\n",
      "Proportion of positive to negative examples = 19.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1157a88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get number of positve and negative examples\n",
    "pos = df[df[\"not_fully_paid\"] == 1].shape[0]\n",
    "neg = df[df[\"not_fully_paid\"] == 0].shape[0]\n",
    "print(f\"Positive examples = {pos}\")\n",
    "print(f\"Negative examples = {neg}\")\n",
    "print(f\"Proportion of positive to negative examples = {(pos / neg) * 100:.2f}%\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(df[\"not_fully_paid\"])\n",
    "plt.xticks((0, 1), [\"Paid fully\", \"Not paid fully\"])\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class counts\", y=1, fontdict={\"fontsize\": 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have only one categorical feature (\"purpose\"). Also, six features have missing values (no missing values in labels feature). Moreover, the data set is pretty imbalanced as expected where positive examples (\"not paid fully\") are only 19%. We'll explain in the next section how to handle all of them after giving an overview of ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2 style=\"font-family: Georgia; font-size:2em;color:purple; font-style:bold\">\n",
    "Modeling</h2><br>\n",
    "**Ensemble methods** can be defined as combining several different models (base learners) into final model (meta learner) to reduce the generalization error. It relies on the assumption that each model would look at a different aspect of the data which yield to capturing part of the truth. Combining good performing models the were trained independently will capture more of the truth than a single model. Therefore, this would result in more accurate predictions and lower generalization errors.\n",
    "- Almost always ensemble model performance gets improved as we add more models.\n",
    "- Try to combine models that are as much different as possible. This will reduce the correlation between the models that will improve the performance of the ensemble model that will lead to significantly outperform the best model. In the worst case where all models are perfectly correlated, the ensemble would have the same performance as the best model and sometimes even lower if some models are very bad. As a result, pick models that are as good as possible.\n",
    "\n",
    "Diﬀerent ensemble methods construct the ensemble of models in diﬀerent ways. Below are the most common methods:\n",
    "- Averaging the predictions of all models.\n",
    "- Bagging: build different models on different datasets and then take the majority vote from all the models. Given the original dataset, we sample with replacement to get the same size of the original dataset. Therefore, each dataset will include, on average, 2/3 of the original data and the rest 1/3 will be duplicates. Since each model will be built on a different dataset, it can be seen as a different model. It reduces the variances of decision trees by reducing the likelihood of strong features to picked on every split. In other word, it reduces the number of features available at each split from $n$ to $n/2$ or $log(n)$.\n",
    "- Boosting: build models sequentially. That means each model learns from the residuals of the previous model. The output will be all output of each single model weighted by the learning rate ($\\lambda$). It reduces the bias resulted from bagging by learning sequentially from residuals of previous trees (models). \n",
    "- Stacking: Build k models called base learners. Then fit a model to the output of the base learners to predict the final output. We'll explain more in \"Modeling\" section of how it works.\n",
    "\n",
    "Since we'll be using Random Fores (bagging) and Gradient Boosting (boosting) classifiers as base learners in the ensemble model, we'll illustrate only averaging and stacking ensemble methods. Therefore, modeling parts would be consisted of three parts:\n",
    "- Strategies to deal with missing values.\n",
    "- Strategies to deal with imbalanced datasets.\n",
    "- Build Ensemble models.\n",
    "\n",
    "Before going further, the following data preprocessing steps will be applicable to all models:\n",
    "1. Create dummy variables from the feature \"purpose\" since its nominal (not ordinal) categorical variable. It's also a good practice to drop the first one to avoid linear dependency between the resulted features since some algorithms may struggle with this issue.\n",
    "3. Split the data into training set (70%), and test set (30%). Training set will be used to fit the model, and test set will be to evaluate the best model to get an estimation of generalization error. Instead of having validation set to tune hyperparameters and evaluate different models, we'll use 10-folds cross validation because it's more reliable estimate of generalization error.\n",
    "2. Standardize the data. We'll be using `RobustScaler` so that the standarization will be less influenced by the outliers, i.e. more robust. It centers the data around the median and scale it using *interquartile range (IQR)*. This step will be included in the pipelines for each model as a transformer so we will not do it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>not_fully_paid</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_policy  int_rate  installment  log_annual_inc    dti  fico  \\\n",
       "0              1    0.1189       829.10       11.350407  19.48   737   \n",
       "1              1    0.1071       228.22       11.082143  14.29   707   \n",
       "2              1    0.1357       366.86       10.373491  11.63   682   \n",
       "3              1    0.1008       162.34       11.350407   8.10   712   \n",
       "4              1    0.1426       102.92       11.299732  14.97   667   \n",
       "\n",
       "   days_with_cr_line  revol_bal  revol_util  inq_last_6mths  delinq_2yrs  \\\n",
       "0        5639.958333      28854        52.1             0.0          0.0   \n",
       "1        2760.000000      33623        76.7             0.0          0.0   \n",
       "2        4710.000000       3511        25.6             1.0          0.0   \n",
       "3        2699.958333      33667        73.2             1.0          0.0   \n",
       "4        4066.000000       4740        39.5             0.0          1.0   \n",
       "\n",
       "   pub_rec  not_fully_paid  purpose_credit_card  purpose_debt_consolidation  \\\n",
       "0      0.0               0                    0                           1   \n",
       "1      0.0               0                    1                           0   \n",
       "2      0.0               0                    0                           1   \n",
       "3      0.0               0                    0                           1   \n",
       "4      0.0               0                    1                           0   \n",
       "\n",
       "   purpose_educational  purpose_home_improvement  purpose_major_purchase  \\\n",
       "0                    0                         0                       0   \n",
       "1                    0                         0                       0   \n",
       "2                    0                         0                       0   \n",
       "3                    0                         0                       0   \n",
       "4                    0                         0                       0   \n",
       "\n",
       "   purpose_small_business  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables from the feature purpose\n",
    "df = pd.get_dummies(df, columns=[\"purpose\"], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3 style=\"font-family: Georgia; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Strategies to deal with missing value</h3><br>\n",
    "Almost always real world data sets have missing values. This can be due, for example, users didn't fill some part of the forms or some transformations happened while collecting and cleaning the data before they send it to you. Sometimes missing values are informative and weren't generated randomly. Therefore, it's a good practice to add binary features to check if there is missing values in each row for each feature that has missing values. In our case, six features have missing values so we would add six binary features one for each feature. For example, \"log_annual_inc\" feature has missing values, so we would add a feature \"is_log_annual_inc_missing\" that takes the values $\\in \\{0, 1\\}$. Good thing is that the missing values are in the predictors only and not the labels. Below are some of the most common strategies for dealing with missing values:\n",
    "- Simply delete all examples that have any missing values. This is usually done if the missing values are very small compared to the size of the data set and the missing values were random. In other words, the added binary features did improve the model. One disadvantage for this strategy is that the model will throw an error when test data has missing values at prediction.\n",
    "- Impute the missing values using the mean of each feature separately.\n",
    "- Impute the missing values using the median of each feature separately.\n",
    "- Use *Multivariate Imputation by Chained Equations (MICE)*. The main disadvantage of MICE is that we can't use it as a transformer in sklearn pipelines and it requires to use the full data set when imputing the missing values. This means that there will be a risk of data leakage since we're using both training and test sets to impute missing values. The followig steps explain how MICE works:\n",
    "    - First step: impute the missing values using the mean of each feature separatelty.\n",
    "    - Second step: for each feature that has missing values, we take all other features as predictors (including the ones that had missing values) and try to predict the values for this feature using linear regression for example. The predicted values will replace the old values for that feature. We do this for all features that have missing values, i.e. each feature will be used once as a target variable to predict its values and the rest of the time as a predictor to predict other features's values. Therefore, one complete cycle (iteration) will be done once we run the model $k$ times to predict the $k$ features that have missing values. For our data set, each iteration will run the linear regression 6 times to predict the 6 features.\n",
    "    - Thired step: Repeat step 2 until there is not much of change between predictions.\n",
    "- Impute the missing values using K-Nearest Neighbors. We compute distance between all examples (excluding missing values) in the data set and take the average of k-nearest neighbors of each missing value. There's no implementation for it yet in sklearn and it's pretty inefficient to compute it since we'll have to go through all examples to calculate distances. Therefore, we'll skip this strategy in this notebook.\n",
    "\n",
    "To evaluate each strategy, we'll use *Random Forest* classifier with hyperparameters' values guided by [Data-driven Advice for Applying Machine Learning to Bioinformatics Problems](https://arxiv.org/pdf/1708.05070.pdf) as a starting point.\n",
    "\n",
    "Let's first create binary features for missing values and then prepare the data for each strategy discussed above. Next, we'll compute the 10-folds cross validation *AUC* score for all the models using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_annual_inc sum of nans: 4\n",
      "days_with_cr_line sum of nans: 29\n",
      "revol_util sum of nans: 62\n",
      "inq_last_6mths sum of nans: 29\n",
      "delinq_2yrs sum of nans: 29\n",
      "pub_rec sum of nans: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>is_log_annual_inc_missing</th>\n",
       "      <th>is_days_with_cr_line_missing</th>\n",
       "      <th>is_revol_util_missing</th>\n",
       "      <th>is_inq_last_6mths_missing</th>\n",
       "      <th>is_delinq_2yrs_missing</th>\n",
       "      <th>is_pub_rec_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_policy  int_rate  installment  log_annual_inc    dti  fico  \\\n",
       "0              1    0.1189       829.10       11.350407  19.48   737   \n",
       "1              1    0.1071       228.22       11.082143  14.29   707   \n",
       "2              1    0.1357       366.86       10.373491  11.63   682   \n",
       "3              1    0.1008       162.34       11.350407   8.10   712   \n",
       "4              1    0.1426       102.92       11.299732  14.97   667   \n",
       "\n",
       "   days_with_cr_line  revol_bal  revol_util  inq_last_6mths  \\\n",
       "0        5639.958333      28854        52.1             0.0   \n",
       "1        2760.000000      33623        76.7             0.0   \n",
       "2        4710.000000       3511        25.6             1.0   \n",
       "3        2699.958333      33667        73.2             1.0   \n",
       "4        4066.000000       4740        39.5             0.0   \n",
       "\n",
       "          ...          purpose_educational  purpose_home_improvement  \\\n",
       "0         ...                            0                         0   \n",
       "1         ...                            0                         0   \n",
       "2         ...                            0                         0   \n",
       "3         ...                            0                         0   \n",
       "4         ...                            0                         0   \n",
       "\n",
       "   purpose_major_purchase  purpose_small_business  is_log_annual_inc_missing  \\\n",
       "0                       0                       0                          0   \n",
       "1                       0                       0                          0   \n",
       "2                       0                       0                          0   \n",
       "3                       0                       0                          0   \n",
       "4                       0                       0                          0   \n",
       "\n",
       "   is_days_with_cr_line_missing  is_revol_util_missing  \\\n",
       "0                             0                      0   \n",
       "1                             0                      0   \n",
       "2                             0                      0   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   is_inq_last_6mths_missing  is_delinq_2yrs_missing  is_pub_rec_missing  \n",
       "0                          0                       0                   0  \n",
       "1                          0                       0                   0  \n",
       "2                          0                       0                   0  \n",
       "3                          0                       0                   0  \n",
       "4                          0                       0                   0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary features to check if the example is has missing values for all features that have missing values\n",
    "for feature in df.columns:\n",
    "    if np.any(np.isnan(df[feature])):\n",
    "        df[\"is_\" + feature + \"_missing\"] = np.isnan(df[feature]) * 1\n",
    "        print(f\"{feature} sum of nans: {np.isnan(df[feature]).sum()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shapes: ((7662, 24), (1916, 24))\n",
      "After dropping NAs: ((7611, 18), (1905, 18))\n",
      "MICE data shapes: ((7662, 24), (1916, 24))\n"
     ]
    }
   ],
   "source": [
    "# Original Data\n",
    "X = df.loc[:, df.columns != \"not_fully_paid\"].values\n",
    "y = df.loc[:, df.columns == \"not_fully_paid\"].values.flatten()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\n",
    "print(f\"Original data shapes: {X_train.shape, X_test.shape}\")\n",
    "\n",
    "# Drop NA and remove binary columns\n",
    "train_indices_na = np.max(np.isnan(X_train), axis=1)\n",
    "test_indices_na = np.max(np.isnan(X_test), axis=1)\n",
    "X_train_dropna, y_train_dropna = X_train[~train_indices_na, :][:, :-6], y_train[~train_indices_na]\n",
    "X_test_dropna, y_test_dropna = X_test[~test_indices_na, :][:, :-6], y_test[~test_indices_na]\n",
    "print(f\"After dropping NAs: {X_train_dropna.shape, X_test_dropna.shape}\")\n",
    "\n",
    "# MICE data\n",
    "mice = fancyimpute.MICE(verbose=0)\n",
    "X_mice = mice.complete(X)\n",
    "X_train_mice, X_test_mice, y_train_mice, y_test_mice = train_test_split(\n",
    "    X_mice, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\n",
    "print(f\"MICE data shapes: {X_train_mice.shape, X_test_mice.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mBaseline model's average AUC: 0.651\n",
      "\u001b[1m\u001b[94mMean imputation model's average AUC: 0.650\n",
      "\u001b[1m\u001b[94mMedian imputation model's average AUC: 0.650\n",
      "\u001b[1m\u001b[94mMICE imputation model's average AUC: 0.652\n"
     ]
    }
   ],
   "source": [
    "# Build random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_features=0.25,\n",
    "                                criterion=\"entropy\",\n",
    "                                class_weight=\"balanced\")\n",
    "# Build base line model -- Drop NA's\n",
    "pip_baseline = make_pipeline(RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_baseline,\n",
    "                         X_train_dropna, y_train_dropna,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mBaseline model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with mean imputation\n",
    "pip_impute_mean = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                                RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_impute_mean,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mMean imputation model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with median imputation\n",
    "pip_impute_median = make_pipeline(Imputer(strategy=\"median\"),\n",
    "                                  RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_impute_median,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mMedian imputation model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model using MICE imputation\n",
    "pip_impute_mice = make_pipeline(RobustScaler(), rf_clf)\n",
    "scores = cross_val_score(pip_impute_mice,\n",
    "                         X_train_mice, y_train_mice,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mMICE imputation model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1227d1f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit RF to plot feature importances\n",
    "rf_clf.fit(RobustScaler().fit_transform(Imputer(strategy=\"median\").fit_transform(X_train)), y_train)\n",
    "\n",
    "# Plot features importance\n",
    "importances = rf_clf.feature_importances_\n",
    "indices = np.argsort(rf_clf.feature_importances_)[::-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, 25), importances[indices], align=\"center\")\n",
    "plt.xticks(range(1, 25), df.columns[df.columns != \"not_fully_paid\"][indices], rotation=90)\n",
    "plt.title(\"Feature Importance\", {\"fontsize\": 16});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guided by the 10-fold cross validation *AUC* scores, it looks like all strategies have comparable results and missing values were generated randomly. Also, the added six binary features showed no importance when plotting feature importances from *Random Forest* classifier. Therefore, it's safe to drop those features and use *Median Imputation* method as a transformer later on in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop generated binary features\n",
    "X_train = X_train[:, :-6]\n",
    "X_test = X_test[:, :-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3 style=\"font-family: Georgia; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Strategies to deal with imbalanced data</h3><br>\n",
    "Classification problems in most real world applications have imbalanced data sets. In other words, the positive examples (minority class) are a lot less than negative examples (majority class). We can see that in spam detection, ads click, loan approvals, etc. In our example, the positive examples (people who didn't fully paid) were only 19% from the total examples. Therefore, accuracy is no longer a good measure of performance for different models because we simply predict all examples to belong to the negative class, we achieve 81% accuracy. Better metrics for imbalanced data sets are *AUC* (area under the ROC curve) and f1-score. However, that's not enough because class imbalance influences a learning algorithm during training by making the decision rule biased towards the majority class by implicitly learns a model that optimizes the predictions based on the majority class in the dataset. As a result, we'll explore different methods to overcome class imbalance problem.\n",
    "- Under-sample: under-sample the majority class w/o replacement by making the number of positive and negative examples equal. One of the drawbacks of under-sampling is that it ignores a good portion of training data that has valuable information. In our example, it would loose around 6500 examples. However, it's very fast to train.\n",
    "- Over-sample: over-sample the minority class w/o replacement by making the number of positive and negative examples equal. We'll add around 6500 samples from the training data set with this strategy. It's a lot more computationally expensive than under-sampling. Also, it's more prune to overfitting due repeated examples.\n",
    "- Easy Ensemble: sample several subsets from the majority class, build a classifier on top of each sampled data, and combine the output of all classifiers. More details can be found [here](http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tsmcb09.pdf)\n",
    "- Synthetic minority over-sampling technique (SMOTE): It over-samples the minority class but using synthesized examples. It operates on feature space not the data space. Here how it works:\n",
    "    - Compute the k-nearest neighbors for all minority samples.\n",
    "    - Randomly choose number between 1-k.\n",
    "    - For each feature:\n",
    "        - Compute the difference between minority sample and its randomly chosen neighbor (from previous step).\n",
    "        - Multiple the difference by random number between 0 and 1.\n",
    "        - Add the obtained feature to the synthesized sample attributes\n",
    "    - Repeat the above until we get the number of synthesized samples needed. More information can be found [here](https://www.jair.org/media/953/live-953-2037-jair.pdf).\n",
    "In most applications, misclassifying the minority class (false negative) is a lot more expensive than misclassifying the majority class (false positive). In the context of lending, loosing money by lending to a risky borrower who is more likely to not fully pay the loan back is a lot more costly than missing the opportunity of lending to trust-worthy borrower (less risky).\n",
    "\n",
    "There are other methods such as `EditedNearestNeighbors` and `CondensedNearestNeighbors` that we will not cover in this notebook and are rarely used in practice. We'll evaluate all the above methods plus the original model without resampling as a baseline model using the same *Random Forest* classifier we used in the missing values section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mOriginal model's average AUC: 0.653\n",
      "\u001b[1m\u001b[94mUnder-sampled model's average AUC: 0.652\n",
      "\u001b[1m\u001b[94mOver-sampled model's average AUC: 0.647\n",
      "\u001b[1m\u001b[94mEasyEnsemble model's average AUC: 0.666\n",
      "\u001b[1m\u001b[94mSMOTE model's average AUC: 0.641\n"
     ]
    }
   ],
   "source": [
    "# Build random forest classifier (same config)\n",
    "rf_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_features=0.25,\n",
    "                                criterion=\"entropy\",\n",
    "                                class_weight=\"balanced\")\n",
    "\n",
    "# Build model with no sampling\n",
    "pip_orig = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                         RobustScaler(),\n",
    "                         rf_clf)\n",
    "scores = cross_val_score(pip_orig,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mOriginal model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with undersampling\n",
    "pip_undersample = imb_make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                                    RobustScaler(),\n",
    "                                    RandomUnderSampler(), rf_clf)\n",
    "scores = cross_val_score(pip_undersample,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mUnder-sampled model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with oversampling\n",
    "pip_oversample = imb_make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                                    RobustScaler(),\n",
    "                                    RandomOverSampler(), rf_clf)\n",
    "scores = cross_val_score(pip_oversample,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mOver-sampled model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with EasyEnsemble\n",
    "resampled_rf = BalancedBaggingClassifier(base_estimator=rf_clf,\n",
    "                                         n_estimators=100, random_state=123)\n",
    "pip_resampled = make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(), resampled_rf)\n",
    "                             \n",
    "scores = cross_val_score(pip_resampled,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mEasyEnsemble model's average AUC: {scores.mean():.3f}\")\n",
    "\n",
    "# Build model with SMOTE\n",
    "pip_smote = imb_make_pipeline(Imputer(strategy=\"mean\"),\n",
    "                              RobustScaler(),\n",
    "                              SMOTE(), rf_clf)\n",
    "scores = cross_val_score(pip_smote,\n",
    "                         X_train, y_train,\n",
    "                         scoring=\"roc_auc\", cv=10)\n",
    "print(f\"\\033[1m\\033[94mSMOTE model's average AUC: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyEnsemble method has the highest 10-folds CV with average AUC = 0.666. Therefore, we'll use it when building ensemble models in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3 style=\"font-family: Georgia; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Build Ensemble methods</h3><br>\n",
    "We'll build ensemble models using three different models as base learners where each one belongs to different modeling family:\n",
    "- K-Nearest neighbors: non-parametric lazy learner.\n",
    "- Logistic regression: linear-based model.\n",
    "- Extra Gradient Boosting Classifier: tree-based model.\n",
    "\n",
    "The ensemble models will be built using two different methods:\n",
    "- Averaging base learners predictions.\n",
    "- Stacking: fit a logistic regression model on the predictions of the base learners. Such model is called meta-learner.\n",
    "\n",
    "We will not tune the hyperparameters of each of the base learners as well as the meta-learner; however, we will use some of the values recommended by the [Pennsylvania Benchmarking Paper](https://arxiv.org/pdf/1708.05070.pdf). We'll start by first calculating the 10-folds cross validation of each each of the base learners and then build the ensemble models to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2452, 18), (2452,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute the missing data using features means\n",
    "imp = Imputer()\n",
    "imp.fit(X_train)\n",
    "X_train = imp.transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "# Standardize the data\n",
    "std = RobustScaler()\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)\n",
    "\n",
    "# Implement RandomUnderSampler\n",
    "random_undersampler = RandomUnderSampler()\n",
    "X_res, y_res = random_undersampler.fit_sample(X_train, y_train)\n",
    "# Shuffle the data\n",
    "perms = np.random.permutation(X_res.shape[0])\n",
    "X_res = X_res[perms]\n",
    "y_res = y_res[perms]\n",
    "X_res.shape, y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                              learning_rate=0.1,\n",
    "                              n_estimators=100,\n",
    "                              max_depth=3,\n",
    "                              random_state=123)\n",
    "\n",
    "svm_clf = SVC(gamma=0.1,\n",
    "                C=0.01,\n",
    "                kernel=\"poly\",\n",
    "                degree=3,\n",
    "                coef0=10.0,\n",
    "                probability=True)\n",
    "\n",
    "logreg_clf = LogisticRegression(penalty=\"l1\",\n",
    "                                C=50,\n",
    "                                fit_intercept=True)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500,\n",
    "                                max_features=0.25,\n",
    "                                criterion=\"entropy\",\n",
    "                                class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb test AUC score = 0.691\n",
      "svm test AUC score = 0.702\n",
      "rf test AUC score = 0.692\n",
      "avg_ensemble test AUC score = 0.705\n"
     ]
    }
   ],
   "source": [
    "# Fitting voting clf --> average ensemble\n",
    "voting_clf = VotingClassifier([(\"xgb\", xgb_clf),\n",
    "                                (\"svm\", svm_clf),\n",
    "                                (\"rf\", rf_clf)],\n",
    "                                voting=\"soft\")\n",
    "voting_clf.fit(X_res, y_res)\n",
    "xgb_model, svm_model, rf_model = voting_clf.estimators_\n",
    "models = {\"xgb\": xgb_model, \"svm\": svm_model,\n",
    "          \"rf\": rf_model, \"avg_ensemble\": voting_clf}\n",
    "for name, model in models.items():\n",
    "    print(f\"\"\"{name} test AUC score = {roc_auc_score(\n",
    "          y_test, model.predict_proba(X_test)[:, 1]):.3f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb test AUC score = 0.703\n",
      "svm test AUC score = 0.706\n",
      "rf test AUC score = 0.697\n",
      "avg_ensemble test AUC score = 0.709\n"
     ]
    }
   ],
   "source": [
    "resampled_xgb = BalancedBaggingClassifier(base_estimator=xgb_clf,\n",
    "                                         n_estimators=100, random_state=123)\n",
    "resampled_svm = BalancedBaggingClassifier(base_estimator=svm_clf,\n",
    "                                         n_estimators=100, random_state=123)\n",
    "resampled_rf = BalancedBaggingClassifier(base_estimator=rf_clf,\n",
    "                                         n_estimators=100, random_state=123)\n",
    "\n",
    "# Fitting voting clf --> average ensemble\n",
    "voting_clf = VotingClassifier([(\"xgb\", resampled_xgb),\n",
    "                                (\"svm\", resampled_svm),\n",
    "                                (\"rf\", resampled_rf)],\n",
    "                                voting=\"soft\", flatten_transform=True)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "xgb_model, svm_model, rf_model = voting_clf.estimators_\n",
    "models = {\"xgb\": xgb_model, \"svm\": svm_model,\n",
    "          \"rf\": rf_model, \"avg_ensemble\": voting_clf}\n",
    "for name, model in models.items():\n",
    "    print(f\"\"\"{name} test AUC score = {roc_auc_score(\n",
    "          y_test, model.predict_proba(X_test)[:, 1]):.3f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-f577aa7acd38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                   \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                   method=\"transform\")\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mfirst_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msecond_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    678\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    679\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 680\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001b[1;32m    188\u001b[0m                                                  sample_weight=sample_weight)\n\u001b[0;32m--> 189\u001b[0;31m                 for clf in clfs if clf is not None)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/imblearn/ensemble/classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# RandomUnderSampler is not supporting sample_weight. We need to pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 375\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Draw samples, using a mask, and then fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 classes_k, y_encoded[:, k] = np.unique(y[:, k],\n\u001b[0;32m--> 152\u001b[0;31m                                                        return_inverse=True)\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier([(\"xgb\", resampled_xgb),\n",
    "                                (\"svm\", resampled_svm),\n",
    "                                (\"rf\", resampled_rf)],\n",
    "                                voting=\"soft\", flatten_transform=True)\n",
    "\n",
    "first_stack = make_pipeline(voting_clf,\n",
    "                            FunctionTransformer(lambda X: X[:, 1::2]))\n",
    "meta_features = cross_val_predict(first_stack,\n",
    "                                  X_train, y_train,\n",
    "                                  cv=10,\n",
    "                                  method=\"transform\")\n",
    "first_stack.fit(X_train, y_train)\n",
    "second_stack = logreg_clf.fit(meta_features, y_train)\n",
    "roc_auc_score(y_test, second_stack.predict_proba(first_stack.transform(X_test))[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2 style=\"font-family: Georgia; font-size:2em;color:purple; font-style:bold\">\n",
    "Conclusion</h2><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
